% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/generateDictionary.R
\name{generateDictionary}
\alias{generateDictionary}
\alias{generateDictionary.Corpus}
\alias{generateDictionary.DocumentTermMatrix}
\alias{generateDictionary.TermDocumentMatrix}
\alias{generateDictionary.character}
\alias{generateDictionary.data.frame}
\title{Generates dictionary of decisive terms}
\usage{
generateDictionary(x, response, language = "english", alpha = 1,
  s = "lambda.min", family = "gaussian", minWordLength = 3,
  sparsity = 0.9, weighting = function(x) tm::weightTfIdf(x, normalize =
  FALSE), ...)

\method{generateDictionary}{Corpus}(x, response, language = "english",
  alpha = 1, s = "lambda.min", family = "gaussian", minWordLength = 3,
  sparsity = 0.9, weighting = function(x) tm::weightTfIdf(x, normalize =
  FALSE), ...)

\method{generateDictionary}{character}(x, response, language = "english",
  alpha = 1, s = "lambda.min", family = "gaussian", minWordLength = 3,
  sparsity = 0.9, weighting = function(x) tm::weightTfIdf(x, normalize =
  FALSE), ...)

\method{generateDictionary}{data.frame}(x, response, language = "english",
  alpha = 1, s = "lambda.min", family = "gaussian", minWordLength = 3,
  sparsity = 0.9, weighting = function(x) tm::weightTfIdf(x, normalize =
  FALSE), ...)

\method{generateDictionary}{TermDocumentMatrix}(x, response,
  language = "english", alpha = 1, s = "lambda.min",
  family = "gaussian", minWordLength = 3, sparsity = 0.9,
  weighting = function(x) tm::weightTfIdf(x, normalize = FALSE), ...)

\method{generateDictionary}{DocumentTermMatrix}(x, response,
  language = "english", alpha = 1, s = "lambda.min",
  family = "gaussian", minWordLength = 3, sparsity = 0.9,
  weighting = function(x) tm::weightTfIdf(x, normalize = FALSE), ...)
}
\arguments{
\item{x}{A vector of characters, a \code{data.frame}, an object of type 
\code{\link[tm]{Corpus}}, \code{\link[tm]{TermDocumentMatrix}} or
\code{\link[tm]{DocumentTermMatrix}}.}

\item{response}{Response variable including the given gold standard.}

\item{language}{Language used for preprocessing operations (default: 
English).}

\item{alpha}{Abstraction parameter for switching form LASSO regularization
(with default \code{alpha=1}) to ridge regression (\code{alpha=0}). As alternative
options, one can also utilize to an elastic net with any continuous value 
inbetween.}

\item{s}{Value of the parameter lambda at which the LASSO is evaluated. Default
is \code{s="lambda.1se"} which takes the calculated minimum value for \eqn{\lambda} 
and then subtracts one standard error in order to avoid overfitting. This often
results in a better performance than using the minimum value itself given by 
\code{lambda="lambda.min"}.}

\item{family}{Distribution for response variable. Default is \code{family="gaussian"}.
For non-negative counts, use \code{family="poisson"}. For binary variables
\code{family="binomial"}. See \code{\link[glmnet]{glmnet}} for further details.}

\item{minWordLength}{Removes words given a specific minimum length (default: 3). This 
preprocessing is applied when the input is a character vector or a corpus and the
document-term matrix is generated inside the routine.}

\item{sparsity}{A numeric for removing sparse terms in the document-term matrix. The
argument \code{sparsity} specifies the maximal allowed sparsity. Default is 
\code{sparsity=0.9}, however, this is only applied when the document-term matrix
is calculated inside the rotuine.}

\item{weighting}{Weights a document-term matrix by e.g. term frequency - inverse
document frequency (default). Other variants can be used from 
\code{\link[tm]{DocumentTermMatrix}}.}

\item{...}{Additional parameters passed to function for e.g. 
preprocessing or \code{\link[glmnet]{glmnet}}.}
}
\value{
Result is a matrix which sentiment values for each document across
all defined rules
}
\description{
Routine applies LASSO regularization to the document-term matrix in order to 
extract decisive terms that have a statistically significant impact on the 
response variable.
}
\examples{
# Create a vector of strings
documents <- c("This is a good thing!",
               "This is a very good thing!",
               "This is okay.",
               "This is a bad thing.",
               "This is a very bad thing.")
response <- c(1, 0.5, 0, -0.5, -1)

# Generate dictionary with LASSO regularization
dictionary <- generateDictionary(documents, response)

# Show dictionary
dictionary
summary(dictionary)
plot(dictionary)

# Compute in-sample performance
sentiment <- predict(dictionary, documents)
compareToResponse(sentiment, response)
plotSentimentResponse(sentiment, response)

# Generate new dictionary with tf weighting innstead of tf-idf

library(tm)
dictionary <- generateDictionary(documents, response, weighting=weightTf)
sentiment <- predict(dictionary, documents)
compareToResponse(sentiment, response)

# Use instead lambda.min from the LASSO estimation
dictionary <- generateDictionary(documents, response, s="lambda.min")
sentiment <- predict(dictionary, documents)
compareToResponse(sentiment, response)
 
\dontrun{
imdb <- loadImdb()

# Generate Dictionary
dictionary_imdb <- generateDictionary(imdb$Corpus, imdb$Rating, family="poisson")
summary(dictionary_imdb)

compareDictionaries(dictionary_imdb,
                    loadDictionaryGI())
                    
# Show estimated coefficients with Kernel Density Estimation (KDE)
plot(dictionary_imdb)
plot(dictionary_imdb) + xlim(c(-0.1, 0.1))

# Compute in-sample performance
pred_sentiment <- predict(dict_imdb, imdb$Corpus)
compareToResponse(pred_sentiment, imdb$Rating)

# Test a different sparsity parameter
dictionary_imdb <- generateDictionary(imdb$Corpus, imdb$Rating, family="poisson", sparsity=0.99)
summary(dictionary_imdb)
pred_sentiment <- predict(dict_imdb, imdb$Corpus)
compareToResponse(pred_sentiment, imdb$Rating)
}
}
\references{
Proellochs, Feuerriegel and Neumann (2015) \emph{Generating 
Domain-Specific Dictionaries Using Bayesian Learning}, Proceedings of the 
23rd European Conference on Information Systems (ECIS 2015), Muenster, 
Germany. URL: \url{http://dx.doi.org/10.2139/ssrn.2522884}
}
\seealso{
\code{\link{analyzeSentiment}} \code{\link{predict.SentimentDictionaryWeighted}}
\code{\link{plot.SentimentDictionaryWeighted}}  \code{\link{compareToResponse}}
}

